{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7b4e10",
   "metadata": {},
   "source": [
    "# ⚠️⚠️ **Backup your data before you proceed** ⚠️⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7967167",
   "metadata": {},
   "source": [
    "## Transforming GreenDB v0.1 to v0.2\n",
    "\n",
    "We slightly envolved the schema of the GreenDB, making it necessary to converting the existing data.\n",
    "\n",
    "The changes are:\n",
    "1. TODO..\n",
    "\n",
    "This Notebook walks you through the necessary steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d46d18",
   "metadata": {},
   "source": [
    "### Rename `green-db` to `green-db-backup`\n",
    "\n",
    "```sql\n",
    "ALTER TABLE \"green-db\" RENAME TO \"green-db-backup\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffcccd1",
   "metadata": {},
   "source": [
    "\n",
    "### Re-Deploy `worker` Pods\n",
    "\n",
    "These take care of bootstrapping the new tables.\n",
    "\n",
    "```bash\n",
    "make workers-test-deploy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cd0b7",
   "metadata": {},
   "source": [
    "\n",
    "### Copy `Scraping` Data v0.1 to v0.2\n",
    "\n",
    "```sql\n",
    "---- DE ----\n",
    "\n",
    "INSERT INTO \"otto_DE\"\n",
    "\tSELECT \"id\", \"timestamp\", \"merchant\" AS \"source\", \"merchant\", 'DE' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM otto;\n",
    "\t\n",
    "INSERT INTO \"amazon_DE\"\n",
    "\tSELECT \"id\", \"timestamp\", \"merchant\" AS \"source\", \"merchant\", 'DE' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM amazon;\n",
    "\t\n",
    "INSERT INTO \"zalando_DE\"\n",
    "\tSELECT \"id\", \"timestamp\", \"merchant\" AS \"source\", \"merchant\", 'DE' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM zalando;\n",
    "\n",
    "---- FR ----\n",
    "\n",
    "INSERT INTO \"asos_FR\"\n",
    "\tSELECT \"id\", \"timestamp\", \"merchant\" AS \"source\", \"merchant\", 'FR' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM asos;\n",
    "\n",
    "INSERT INTO \"hm_FR\"\n",
    "\tSELECT \"id\", \"timestamp\", \"merchant\" AS \"source\", \"merchant\", 'FR' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM hm;\n",
    "\n",
    "INSERT INTO \"zalando_FR\"\n",
    "\tSELECT \"id\", \"timestamp\", 'zalando' AS \"source\", 'zalando' AS \"merchant\", 'FR' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM zalando_fr;\n",
    "\n",
    "INSERT INTO \"amazon_FR\"\n",
    "\tSELECT \"id\", \"timestamp\", 'amazon' AS \"source\", 'amazon' AS \"merchant\", 'FR' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM amazon_fr;\n",
    "\n",
    "---- GB ----\n",
    "\n",
    "INSERT INTO \"zalando_GB\"\n",
    "\tSELECT \"id\", \"timestamp\", 'zalando' AS \"source\", 'zalando' AS \"merchant\", 'GB' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM zalando_uk;\n",
    "\n",
    "INSERT INTO \"amazon_GB\"\n",
    "\tSELECT \"id\", \"timestamp\", 'amazon' AS \"source\", 'amazon' AS \"merchant\", 'GB' AS country, \"category\", \"url\", \"html\", \"page_type\",\n",
    "\t  CASE \n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t\t ELSE upper(meta_information->>'sex')\n",
    "\t\tEND\n",
    "\t\tAS gender,\n",
    "\t  CASE\n",
    "\t    WHEN meta_information->>'sex' IS NULL THEN NULL\n",
    "\t    ELSE 'ADULT'\n",
    "\t  END\n",
    "\t  AS consumer_lifestage,\n",
    "\t  \"meta_information\"\n",
    "\tFROM amazon_uk;\n",
    "\n",
    "---- Set autoincrement value ----\n",
    "\n",
    "Select setval('\"zalando_DE_id_seq\"'::REGCLASS, (select max(id) FROM \"zalando_DE\"));\n",
    "Select setval('\"zalando_FR_id_seq\"'::REGCLASS, (select max(id) FROM \"zalando_FR\"));\n",
    "Select setval('\"zalando_GB_id_seq\"'::REGCLASS, (select max(id) FROM \"zalando_GB\"));\n",
    "\n",
    "Select setval('\"hm_FR_id_seq\"'::REGCLASS, (select max(id) FROM \"hm_FR\"));\n",
    "\n",
    "Select setval('\"asos_FR_id_seq\"'::REGCLASS, (select max(id) FROM \"asos_FR\"));\n",
    "\n",
    "Select setval('\"otto_DE_id_seq\"'::REGCLASS, (select max(id) FROM \"otto_DE\"));\n",
    "\n",
    "Select setval('\"amazon_FR_id_seq\"'::REGCLASS, (select max(id) FROM \"amazon_FR\"));\n",
    "Select setval('\"amazon_DE_id_seq\"'::REGCLASS, (select max(id) FROM \"amazon_DE\"));\n",
    "Select setval('\"amazon_GB_id_seq\"'::REGCLASS, (select max(id) FROM \"amazon_GB\"));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ffcf0",
   "metadata": {},
   "source": [
    "⚠️ Make sure the data looks like you expect it and delete the `v0.1` tables to save space.\n",
    "\n",
    "```sql\n",
    "DROP TABLE \"amazon\", \"amazon_fr\", \"amazon_uk\", \"asos\", \"hm\", \"otto\", \"zalando\", \"zalando_fr\", \"zalando_uk\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16e3a3",
   "metadata": {},
   "source": [
    "## TODO: Brief description what's necessary\n",
    "\n",
    "- Need to fill new GreenDB columns.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e07167",
   "metadata": {},
   "source": [
    "### Defining Helper and `v0.1` Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"POSTGRES_SCRAPING_USER\"] = \"scraping\"\n",
    "os.environ[\"POSTGRES_SCRAPING_PASSWORD\"] = \"TODO\"\n",
    "os.environ[\"POSTGRES_SCRAPING_HOST\"] = \"127.0.0.1\"\n",
    "os.environ[\"POSTGRES_SCRAPING_PORT\"] = \"5432\"\n",
    "\n",
    "os.environ[\"POSTGRES_GREEN_DB_USER\"] = \"green-db\"\n",
    "os.environ[\"POSTGRES_GREEN_DB_PASSWORD\"] = \"TODO\"\n",
    "os.environ[\"POSTGRES_GREEN_DB_HOST\"] = \"localhost\"\n",
    "os.environ[\"POSTGRES_GREEN_DB_PORT\"] = \"5432\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd09955",
   "metadata": {},
   "source": [
    "### Setup Env Variables\n",
    "\n",
    "... and do not forget to forward the Postgres port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1abf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Optional, Iterator, List\n",
    "\n",
    "from pydantic import BaseModel, conlist\n",
    "from sqlalchemy import ARRAY, BIGINT, INTEGER, NUMERIC, TEXT, TIMESTAMP, Column\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from database.connection import Scraping, Connection, GreenDB\n",
    "from database.tables import __TableMixin, GreenDBBaseTable\n",
    "from core.domain import Product, CurrencyType, CertificateType\n",
    "from core.constants import DATABASE_NAME_GREEN_DB\n",
    "\n",
    "\n",
    "#### Domains ####\n",
    "\n",
    "\n",
    "class ScrapedPageWithoutHTML(BaseModel):\n",
    "    timestamp: datetime\n",
    "    source: str\n",
    "    merchant: str\n",
    "    country: str\n",
    "    url: str\n",
    "    category: str\n",
    "    gender: Optional[str]\n",
    "    consumer_lifestage: Optional[str]\n",
    "\n",
    "    class Config:\n",
    "        orm_mode = True\n",
    "        use_enum_values = True\n",
    "\n",
    "\n",
    "class ProductV1(BaseModel):\n",
    "    timestamp: datetime\n",
    "    url: str\n",
    "    merchant: str\n",
    "    category: str\n",
    "    name: str\n",
    "    description: str\n",
    "    brand: str\n",
    "    sustainability_labels: conlist(CertificateType, min_items=1)  # type: ignore\n",
    "    price: float\n",
    "    currency: CurrencyType\n",
    "    image_urls: List[str]\n",
    "    color: Optional[str]\n",
    "    size: Optional[str]\n",
    "    gtin: Optional[int]\n",
    "    asin: Optional[str]\n",
    "\n",
    "    class Config:\n",
    "        orm_mode = True\n",
    "        use_enum_values = True\n",
    "\n",
    "\n",
    "#### Table ####\n",
    "\n",
    "\n",
    "class GreenDBV1Table(GreenDBBaseTable, __TableMixin):\n",
    "    \"\"\"\n",
    "    Used to access DB table of the V1 structure.\n",
    "    \"\"\"\n",
    "\n",
    "    __tablename__ = \"green-db-backup\"\n",
    "\n",
    "    id = Column(INTEGER, nullable=False, autoincrement=True, primary_key=True)\n",
    "    timestamp = Column(TIMESTAMP, nullable=False)\n",
    "    merchant = Column(TEXT, nullable=False)\n",
    "    category = Column(TEXT, nullable=False)\n",
    "    url = Column(TEXT, nullable=False)\n",
    "    name = Column(TEXT, nullable=False)\n",
    "    description = Column(TEXT, nullable=False)\n",
    "    brand = Column(TEXT, nullable=False)\n",
    "    sustainability_labels = Column(ARRAY(TEXT), nullable=False)\n",
    "    price = Column(NUMERIC, nullable=False)\n",
    "    currency = Column(TEXT, nullable=False)\n",
    "    image_urls = Column(ARRAY(TEXT), nullable=False)\n",
    "    color = Column(TEXT, nullable=True)\n",
    "    size = Column(TEXT, nullable=True)\n",
    "    gtin = Column(BIGINT, nullable=True)\n",
    "    asin = Column(TEXT, nullable=True)\n",
    "\n",
    "\n",
    "#### Connection ####\n",
    "\n",
    "\n",
    "class GreenDBV1(Connection):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        `Connection` for the GreenDB.\n",
    "        Automatically pre-populates the sustainability labels table.\n",
    "        \"\"\"\n",
    "        super().__init__(GreenDBV1Table, DATABASE_NAME_GREEN_DB)\n",
    "\n",
    "    def get_all_v1_products(self) -> Iterator[ProductV1]:\n",
    "        with self._session_factory() as db_session:\n",
    "            query = db_session.query(self._database_class)\n",
    "            return (ProductV1.from_orm(row) for row in query.all())\n",
    "\n",
    "\n",
    "#### Connection Extensions (aka Functions) ####\n",
    "\n",
    "\n",
    "def write_dataframe(greenDB_connection, data_frame):\n",
    "    with greenDB_connection._session_factory() as db_session:\n",
    "        df_len = len(data_frame)\n",
    "\n",
    "        for index, (df_index, product) in enumerate(data_frame.iterrows(), start=1):\n",
    "            try:\n",
    "                db_object = greenDB_connection._database_class(**Product.parse_obj(product).dict())\n",
    "                db_session.add(db_object)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"error for product with index: {df_index}\")\n",
    "                print(e)\n",
    "\n",
    "            # commit every 1000 products and at the end\n",
    "            if (index % 1000 == 0) or (index == df_len):\n",
    "                db_session.commit()\n",
    "                print(f\"Commited {index} products\")\n",
    "\n",
    "\n",
    "def get_scraped_products_without_html(\n",
    "    scraping_connection: Scraping,\n",
    ") -> Iterator[ScrapedPageWithoutHTML]:\n",
    "    with scraping_connection._session_factory() as db_session:\n",
    "        query = db_session.query(\n",
    "            scraping_connection._database_class.timestamp,\n",
    "            scraping_connection._database_class.source,\n",
    "            scraping_connection._database_class.merchant,\n",
    "            scraping_connection._database_class.country,\n",
    "            scraping_connection._database_class.url,\n",
    "            scraping_connection._database_class.category,\n",
    "            scraping_connection._database_class.gender,\n",
    "            scraping_connection._database_class.consumer_lifestage,\n",
    "        ).filter(scraping_connection._database_class.page_type == \"PRODUCT\")\n",
    "        return (ScrapedPageWithoutHTML.from_orm(row) for row in query.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602d85f",
   "metadata": {},
   "source": [
    "### Load GreenDB and Scraping Tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = [\n",
    "    Scraping(\"zalando_DE\"),\n",
    "    Scraping(\"zalando_GB\"),\n",
    "    Scraping(\"zalando_FR\"),\n",
    "    Scraping(\"otto_DE\"),\n",
    "    Scraping(\"hm_FR\"),\n",
    "    Scraping(\"asos_FR\"),\n",
    "    Scraping(\"amazon_DE\"),\n",
    "    Scraping(\"amazon_FR\"),\n",
    "    Scraping(\"amazon_GB\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e97e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraping_tables_v1 = []\n",
    "\n",
    "for connection in connections:\n",
    "    scraping_table_v1_iterator = get_scraped_products_without_html(connection)\n",
    "    scraping_tables_v1.append(pd.DataFrame([product.__dict__ for product in scraping_table_v1_iterator]))\n",
    "\n",
    "scraping_v1 = pd.concat(scraping_tables_v1)\n",
    "\n",
    "\n",
    "scraping_v1_asos = scraping_v1[scraping_v1[\"merchant\"] == \"asos\"].copy()\n",
    "scraping_v1_without_asos = scraping_v1[scraping_v1[\"merchant\"] != \"asos\"].copy()\n",
    "\n",
    "print(f\"Scraped products (all):      {len(scraping_v1)}\")\n",
    "print(f\"Scraped products (Asos):     {len(scraping_v1_asos)}\")\n",
    "print(f\"Scraped products (wo/ Asos): {len(scraping_v1_without_asos)}\")\n",
    "\n",
    "assert len(scraping_v1) == (len(scraping_v1_asos) + len(scraping_v1_without_asos))\n",
    "del scraping_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "greenDBV1 = GreenDBV1()\n",
    "\n",
    "products_v1_iterator = greenDBV1.get_all_v1_products()\n",
    "products_v1 = pd.DataFrame([product.__dict__ for product in products_v1_iterator])\n",
    "\n",
    "products_v1_asos = products_v1[products_v1[\"merchant\"] == \"asos\"].copy()\n",
    "products_v1_without_asos = products_v1[products_v1[\"merchant\"] != \"asos\"].copy()\n",
    "\n",
    "print(f\"Products (all):      {len(products_v1)}\")\n",
    "print(f\"Products (Asos):     {len(products_v1_asos)}\")\n",
    "print(f\"Products (wo/ Asos): {len(products_v1_without_asos)}\")\n",
    "\n",
    "assert len(products_v1) == (len(products_v1_asos) + len(products_v1_without_asos))\n",
    "del products_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d825f",
   "metadata": {},
   "source": [
    "### Join Scraping and GreenDB\n",
    "\n",
    "Since scraping Asos is handled differently, we need to implement it separately.\n",
    "\n",
    "#### Join Products without Asos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(\n",
    "    zip(\n",
    "        scraping_v1_without_asos[\"timestamp\"],\n",
    "        scraping_v1_without_asos[\"url\"],\n",
    "        scraping_v1_without_asos[\"category\"],\n",
    "    )\n",
    ")\n",
    "scraping_v1_without_asos.index = pd.MultiIndex.from_tuples(\n",
    "    indices, names=[\"timestamp\", \"url\", \"category\"]\n",
    ")\n",
    "scraping_v1_without_asos = scraping_v1_without_asos[[\"source\", \"country\", \"gender\", \"consumer_lifestage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_v2_without_asos = products_v1_without_asos.join(\n",
    "    scraping_v1_without_asos, on=[\"timestamp\", \"url\", \"category\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2418b",
   "metadata": {},
   "source": [
    "The shops might list products in multiple categories which we have just assigned to one category. This creates duplicate extracted products so joining the DataFrames, using just `timestamp`, `url` and `category`.\n",
    "We can not fully map instances from scraping table to green-db table but for including `gender` information this is not necessary.\n",
    "If we have multiple products with same `url` and different `category`s assigned to different `gender`, the extracted products are just duplicates of each other, because the product is basically a `UNISEX` product assigned to multiple `category`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c27b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_v2_without_asos = products_v2_without_asos.drop_duplicates(\n",
    "    subset=[\"timestamp\", \"url\", \"source\", \"merchant\", \"category\", \"gender\", \"consumer_lifestage\"]\n",
    ")\n",
    "\n",
    "print(f\"Products without Asos after processing: {len(products_v2_without_asos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc0816c",
   "metadata": {},
   "source": [
    "#### Join Asos Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping\n",
    "\n",
    "scraping_v1_asos[\"product_id\"] = scraping_v1_asos[\"url\"].apply(lambda x: x.split(\"/\")[-1].split(\"?\")[0])\n",
    "scraping_v1_asos[\"product_id\"] = scraping_v1_asos[\"product_id\"].astype(\"int64\")\n",
    "\n",
    "scraping_indices = list(\n",
    "    zip(scraping_v1_asos[\"product_id\"], scraping_v1_asos[\"timestamp\"], scraping_v1_asos[\"category\"])\n",
    ")\n",
    "scraping_v1_asos.index = pd.MultiIndex.from_tuples(\n",
    "    scraping_indices, names=[\"timestamp\", \"url\", \"category\"]\n",
    ")\n",
    "\n",
    "scraping_v1_asos = scraping_v1_asos[[\"source\", \"country\", \"gender\", \"consumer_lifestage\"]]\n",
    "\n",
    "# Products\n",
    "\n",
    "products_v1_asos[\"product_id\"] = products_v1_asos[\"url\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "products_v1_asos[\"product_id\"] = products_v1_asos[\"product_id\"].astype(\"int64\")\n",
    "\n",
    "product_indices = list(\n",
    "    zip(products_v1_asos[\"product_id\"], products_v1_asos[\"timestamp\"], products_v1_asos[\"category\"])\n",
    ")\n",
    "products_v1_asos.index = pd.MultiIndex.from_tuples(\n",
    "    product_indices, names=[\"timestamp\", \"url\", \"category\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_v2_asos = products_v1_asos.join(scraping_v1_asos, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_v2_asos = products_v2_asos.drop_duplicates(\n",
    "    subset=[\"timestamp\", \"url\", \"merchant\", \"category\", \"gender\"]\n",
    ")\n",
    "\n",
    "print(f\"Asos products after processing: {len(products_v2_asos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbf526",
   "metadata": {},
   "source": [
    "#### Combine Products\n",
    "\n",
    "... and some transformations necessary, e.g., `color` are strings often multiple values concatenated with \",\", those will be arrays in the column `colors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16069903",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_v2 = pd.concat([products_v2_without_asos, products_v2_asos])\n",
    "\n",
    "merchant_to_new_merchant = {\n",
    "    \"asos\": \"asos\",\n",
    "    \"amazon\": \"amazon\",\n",
    "    \"amazon_fr\": \"amazon\",\n",
    "    \"amazon_uk\": \"amazon\",\n",
    "    \"zalando\": \"zalando\",\n",
    "    \"zalando_fr\": \"zalando\",\n",
    "    \"zalando_uk\": \"zalando\",\n",
    "    \"otto\": \"otto\",\n",
    "    \"hm\": \"hm\",\n",
    "}\n",
    "\n",
    "products_v2[\"merchant\"] = products_v2[\"merchant\"].apply(\n",
    "    lambda x: merchant_to_new_merchant[x]\n",
    ")\n",
    "products_v2[\"colors\"] = products_v2[\"color\"].apply(lambda x: [x] if x else None)\n",
    "products_v2[\"sizes\"] = products_v2[\"size\"].apply(\n",
    "    lambda sizes: None if sizes == \"None\" or sizes is None else sizes.split(\", \")\n",
    ")\n",
    "products_v2 = products_v2.replace({np.nan: None})\n",
    "\n",
    "print(f\"Overall products (v2): {len(products_v2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890d331",
   "metadata": {},
   "source": [
    "### Insert Products into new GreenDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "greenDB_connection = GreenDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2caaab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_dataframe(greenDB_connection, products_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d6a5e",
   "metadata": {},
   "source": [
    "Setup autoincrement for the green-db.\n",
    "\n",
    "```sql\n",
    "Select setval('\"green-db_id_seq\"'::REGCLASS, (select max(id) FROM \"green-db\"));\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bde05c",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831070e",
   "metadata": {},
   "source": [
    "If everything went well and the tables look good, you can delete the old table:\n",
    "\n",
    "```sql\n",
    "DROP TABLE \"green-db-backup\";\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('workers-tNtV_klg-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbfbed6eb3ea711a1a2e3545e7ac029add56a63574070fa23edda28a069e9e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
